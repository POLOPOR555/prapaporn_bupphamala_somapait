{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a0eb48f-a10d-4f06-97a1-543b2e47c24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "กำลังดึงข้อมูลจากหน้า How-to: https://www.tilda.com/faqs/\n",
      "✅ ดึงข้อมูลจากหน้า How-to สำเร็จแล้ว\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# URL ของแหล่งข้อมูลใหม่ (Tilda Help Center)\n",
    "url = \"https://www.tilda.com/faqs/\"\n",
    "\n",
    "# ส่ง HTTP GET request ไปยัง URL\n",
    "print(f\"กำลังดึงข้อมูลจากหน้า How-to: {url}\")\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # เช็คว่า request สำเร็จหรือไม่\n",
    "\n",
    "# ใช้ BeautifulSoup ในการ parse HTML\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "# จากการตรวจสอบหน้าเว็บใหม่ เนื้อหาหลักจะอยู่ใน <div id=\"allrecords\">\n",
    "# เราจะดึงข้อความจากส่วนนี้แทนที่ของเดิม\n",
    "main_content = soup.find('div', class_='faqs-list')\n",
    "\n",
    "if main_content:\n",
    "    # ดึงข้อความทั้งหมดและทำความสะอาดเล็กน้อย\n",
    "    # separator='\\n' ช่วยให้แต่ละบรรทัดแยกจากกัน ทำให้แบ่ง chunk ได้ดีขึ้น\n",
    "    document_text = main_content.get_text(separator='\\n', strip=True)\n",
    "    print(\"✅ ดึงข้อมูลจากหน้า How-to สำเร็จแล้ว\")\n",
    "    # print(\"\\n--- ตัวอย่างข้อมูลที่ดึงได้ ---\")\n",
    "    # print(document_text[:500]) # แสดงผล 500 ตัวอักษรแรก\n",
    "else:\n",
    "    raise ValueError(\"ไม่พบเนื้อหาส่วน <div id='allrecords'> ในหน้าที่ระบุ\")\n",
    "print(document_text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e9ec8d-4f0b-44e7-bd62-793e63d05d83",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# สร้าง instance ของ Text Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "278479b4-54ca-4408-a9c5-240fefe59045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "กำลังแบ่งข้อมูลเป็นส่วนย่อย (Chunking)...\n",
      "✅ แบ่งข้อมูลออกเป็น 73 chunks สำเร็จ\n",
      "Company\n",
      "Is Tilda an Indian Company?\n",
      "Tilda is a British company that was founded by a Ugandan family who migrated to the UK back in the ’70s. Tracing back to its Indian roots, the Thakrar family wanted to bring authentic ingredients\n",
      "family wanted to bring authentic ingredients they loved back home to the table for families to enjoy. 50 years on, Tilda strongly remains to be a household brand amongst different communities.\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,  # ขนาดของแต่ละ chunk (ตัวอักษร)\n",
    "    chunk_overlap=50, # ขนาดของส่วนที่คาบเกี่ยวกันระหว่าง chunk\n",
    "    length_function=len,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d557a9fc-6a75-4a4b-96dd-c2a35c6fdee5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ทำการแบ่งเอกสาร"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f60285a-8051-4d02-8384-0f8cb35a3f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nกำลังแบ่งข้อมูลเป็นส่วนย่อย (Chunking)...\")\n",
    "chunks = text_splitter.split_text(document_text)\n",
    "print(f\"✅ แบ่งข้อมูลออกเป็น {len(chunks)} chunks สำเร็จ\")\n",
    "\n",
    "# print(\"\\n--- ตัวอย่าง Chunk แรก ---\")\n",
    "print(chunks[0])\n",
    "print(chunks[1])\n",
    "print(chunks[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9875bf07-7ffd-4cb0-8e7b-fe7ea143611a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ขั้นตอนที่ 1: สร้าง Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f97bd72-cd74-4fd4-bf4a-f876d32d6ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# สมมติว่าคุณมีตัวแปร 'chunks' ที่เป็น list ของข้อความที่แบ่งแล้ว\n",
    "# chunks = [\"Company\", \"Is Tilda an Indian Company?\", \"Tilda is a British company...\", ...]\n",
    "\n",
    "# เราต้องแปลงข้อความแต่ละ chunk ให้เป็น Vector ที่สื่อความหมาย\n",
    "# เราจะใช้โมเดลจาก OpenAI ในการทำสิ่งนี้\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-xxxxxxxxxx\"\n",
    "\n",
    "print(\"\\nกำลังสร้าง Embedding Model...\")\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "print(\"✅ Embedding Model พร้อมใช้งาน\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abb6aeb-a6d1-4e26-b854-a6f22f635c1b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ขั้นตอนที่ 2: จัดเก็บลงใน Vector Store (ChromaDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1101ae96-2c4d-4aed-9414-cc7f467010f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# นำข้อความ (chunks) พร้อมกับ Embedding ที่สร้างขึ้น ไปเก็บใน ChromaDB\n",
    "# ChromaDB จะทำหน้าที่เป็นฐานข้อมูลที่ให้เราค้นหาความหมายที่ใกล้เคียงได้\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "print(\"\\nกำลังสร้าง Vector Store ด้วย ChromaDB...\")\n",
    "# LangChain จะทำการ Embed และจัดเก็บข้อมูลลงใน ChromaDB ให้โดยอัตโนมัติ\n",
    "# เราใช้ .from_texts เพราะว่า 'chunks' ของเราเป็น list ของ string\n",
    "vectorstore = Chroma.from_texts(texts=chunks, embedding=embedding_model)\n",
    "print(\"✅ Vector Store สร้างเสร็จสมบูรณ์\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36523cb-cd56-4e76-b616-5a1939ad2dc7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ขั้นตอนที่ 3: สร้าง RAG Chain เพื่อถาม-ตอบ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8fad754f-30f5-466e-b777-0a643e0dd556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "กำลังสร้าง Embedding Model...\n",
      "✅ Embedding Model พร้อมใช้งาน\n",
      "\n",
      "กำลังสร้าง Vector Store ด้วย ChromaDB...\n",
      "✅ Vector Store สร้างเสร็จสมบูรณ์\n",
      "\n",
      "กำลังสร้าง RAG Chain...\n",
      "✅ RAG Chain พร้อมสำหรับถามคำถาม!\n"
     ]
    }
   ],
   "source": [
    "# ส่วนนี้คือการประกอบร่างระบบทั้งหมดเข้าด้วยกัน\n",
    "# 1. Retriever: ตัวค้นหาข้อมูลจาก Vector Store\n",
    "# 2. LLM: ตัวสร้างคำตอบ (เราจะใช้ GPT)\n",
    "# 3. Prompt: คำสั่งที่บอกให้ LLM ตอบคำถามโดยอิงจากข้อมูลที่ Retriever ค้นเจอ\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "print(\"\\nกำลังสร้าง RAG Chain...\")\n",
    "\n",
    "# 3.1) กำหนด LLM ที่จะใช้\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 3.2) สร้าง Retriever จาก Vector Store ของเรา\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 3.3) สร้าง Prompt Template เพื่อสั่งให้ LLM ตอบจาก context ที่ให้ไป\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "ตอบคำถามต่อไปนี้โดยอ้างอิงจากบริบท (context) ที่ให้มาเท่านั้น\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "คำถาม: {input}\n",
    "\"\"\")\n",
    "\n",
    "# 3.4) สร้าง Chain ที่เชื่อมทุกอย่างเข้าด้วยกัน\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "print(\"✅ RAG Chain พร้อมสำหรับถามคำถาม!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d43725-47b8-46bc-912b-ac6335d7e734",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ขั้นตอนที่ 4: ทดลองถามคำถาม"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18bb53a4-6dbd-425b-b4b7-e7080c675527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "❓ คำถาม: Is Tilda an Indian company?\n",
      "\n",
      "💡 คำตอบ:\n",
      "No, Tilda is a British company.\n",
      "\n",
      "--- ข้อมูลอ้างอิง (Context) ---\n",
      "- Company\n",
      "Is Tilda an Indian Company?\n",
      "- Tilda is a British company that was founded by a Ugandan family who migrated to the UK back in the ’70s. Tracing back to its Indian roots, the Thakrar family wanted to bring authentic ingredients\n",
      "- What does Tilda stand for?\n",
      "Tilda is the amalgamation of the names Tila and Daksha, the daughters of the founders. Learn more about Tilda’s\n",
      "history\n",
      "- family wanted to bring authentic ingredients they loved back home to the table for families to enjoy. 50 years on, Tilda strongly remains to be a household brand amongst different communities.\n"
     ]
    }
   ],
   "source": [
    "# ลองถามคำถามที่คิดว่ามีคำตอบอยู่ในข้อมูลที่เราดึงมา\n",
    "\n",
    "question = \"Is Tilda an Indian company?\" # หรือ \"ทิลด้าเป็นบริษัทของอินเดียหรือไม่\"\n",
    "\n",
    "print(f\"\\n❓ คำถาม: {question}\")\n",
    "\n",
    "# เรียกใช้ Chain เพื่อหาคำตอบ\n",
    "response = rag_chain.invoke({\"input\": question})\n",
    "\n",
    "# แสดงผลลัพธ์\n",
    "print(\"\\n💡 คำตอบ:\")\n",
    "print(response[\"answer\"])\n",
    "\n",
    "# (ตัวเลือกเสริม) ดูว่าระบบไปค้นเจอข้อมูลส่วนไหนมาใช้ตอบ\n",
    "print(\"\\n--- ข้อมูลอ้างอิง (Context) ---\")\n",
    "for doc in response[\"context\"]:\n",
    "    print(f\"- {doc.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d913c4cc-9777-43ea-80f8-6d5dc4c0b0b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
